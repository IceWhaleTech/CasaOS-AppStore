name: llama-factory-nvidia
services:
  llama-factory-nvidia:
    image: hiyouga/llamafactory:0.9.4
    container_name: llama-factory-nvidia
    ports:
      - target: 7860
        published: "18877"
        protocol: tcp
    tty: true
    stdin_open: true
    command: [
      "llamafactory-cli",
      "webui"
    ]
    deploy:
      resources:
        reservations:
          memory: 6G
          devices:
            - driver: nvidia
              count: "all"
              capabilities: [gpu]
    restart: unless-stopped
    x-casaos:
      ports:
        - container: "7860"
          description:
            de_DE: LLaMA Factory Web UI Port
            el_GR: Θύρα Διεπαφής Ιστού LLaMA Factory
            en_GB: LLaMA Factory Web UI Port
            en_US: LLaMA Factory Web UI Port
            fr_FR: Port de l'Interface Web LLaMA Factory
            hr_HR: LLaMA Factory Web UI Port
            it_IT: Porta Interfaccia Web LLaMA Factory
            ja_JP: LLaMA Factory Web UI ポート
            ko_KR: LLaMA Factory 웹 UI 포트
            nb_NO: LLaMA Factory Web UI Port
            pt_PT: Porta da Interface Web LLaMA Factory
            ru_RU: Порт веб-интерфейса LLaMA Factory
            sv_SE: LLaMA Factory webbgränssnitt port
            tr_TR: LLaMA Factory Web Arayüzü Portu
            zh_CN: LLaMA Factory Web UI 端口

x-casaos:
  architectures:
    - amd64
  author: hiyouga
  category: AI
  description:
    de_DE: |
      LLaMA Factory ist ein umfassendes Framework für das Fine-Tuning von Large Language Models (LLMs) mit über 100 unterstützten Modellen. Es bietet eine benutzerfreundliche Web-Oberfläche und leistungsstarke Trainingsmethoden wie LoRA, QLoRA und Full-Parameter-Training.

      **Hauptfunktionen:**
      - Unterstützung für 100+ LLMs einschließlich LLaMA, Mistral, Qwen und mehr
      - Mehrere Fine-Tuning-Methoden (LoRA, QLoRA, Full, Freeze)
      - Intuitive Web-UI für einfache Modellverwaltung
      - Integrierter API-Server für Modellinferenz
      - Multi-GPU-Training-Unterstützung
      - Quantisierung und Modellexport

      **Hardwareanforderungen:**
      - GPU: NVIDIA GPU mit CUDA-Unterstützung erforderlich

      **Weitere Informationen:**
      - [GitHub Repository](https://github.com/hiyouga/LLaMA-Factory)
      - [Dokumentation](https://llamafactory.readthedocs.io/)
    el_GR: |
      Το LLaMA Factory είναι ένα ολοκληρωμένο πλαίσιο για την εκπαίδευση μεγάλων γλωσσικών μοντέλων (LLMs) με υποστήριξη για πάνω από 100 μοντέλα. Παρέχει μια φιλική προς το χρήστη διεπαφή ιστού και ισχυρές μεθόδους εκπαίδευσης όπως LoRA, QLoRA και πλήρης εκπαίδευση παραμέτρων.

      **Κύρια Χαρακτηριστικά:**
      - Υποστήριξη για 100+ LLMs συμπεριλαμβανομένων LLaMA, Mistral, Qwen και άλλων
      - Πολλαπλές μέθοδοι fine-tuning (LoRA, QLoRA, Full, Freeze)
      - Διαισθητικό Web UI για εύκολη διαχείριση μοντέλων
      - Ενσωματωμένος διακομιστής API για συμπερασμό μοντέλων
      - Υποστήριξη εκπαίδευσης πολλαπλών GPU
      - Κβαντοποίηση και εξαγωγή μοντέλων

      **Απαιτήσεις Υλικού:**
      - GPU: Απαιτείται NVIDIA GPU με υποστήριξη CUDA

      **Περισσότερες Πληροφορίες:**
      - [Αποθετήριο GitHub](https://github.com/hiyouga/LLaMA-Factory)
      - [Τεκμηρίωση](https://llamafactory.readthedocs.io/)
    en_GB: |
      LLaMA Factory is a comprehensive framework for fine-tuning Large Language Models (LLMs) with support for over 100 models. It provides a user-friendly web interface and powerful training methods including LoRA, QLoRA, and full-parameter training.

      **Key Features:**
      - Support for 100+ LLMs including LLaMA, Mistral, Qwen, and more
      - Multiple fine-tuning methods (LoRA, QLoRA, Full, Freeze)
      - Intuitive Web UI for easy model management
      - Built-in API server for model inference
      - Multi-GPU training support
      - Quantization and model export capabilities

      **Hardware Requirements:**
      - GPU: NVIDIA GPU with CUDA support required

      **Learn More:**
      - [GitHub Repository](https://github.com/hiyouga/LLaMA-Factory)
      - [Documentation](https://llamafactory.readthedocs.io/)
    en_US: |
      LLaMA Factory is a comprehensive framework for fine-tuning Large Language Models (LLMs) with support for over 100 models. It provides a user-friendly web interface and powerful training methods including LoRA, QLoRA, and full-parameter training.

      **Key Features:**
      - Support for 100+ LLMs including LLaMA, Mistral, Qwen, and more
      - Multiple fine-tuning methods (LoRA, QLoRA, Full, Freeze)
      - Intuitive Web UI for easy model management
      - Built-in API server for model inference
      - Multi-GPU training support
      - Quantization and model export capabilities

      **Hardware Requirements:**
      - GPU: NVIDIA GPU with CUDA support required

      **Learn More:**
      - [GitHub Repository](https://github.com/hiyouga/LLaMA-Factory)
      - [Documentation](https://llamafactory.readthedocs.io/)
    fr_FR: |
      LLaMA Factory est un framework complet pour l'ajustement fin des grands modèles de langage (LLMs) avec prise en charge de plus de 100 modèles. Il fournit une interface web conviviale et des méthodes d'entraînement puissantes, notamment LoRA, QLoRA et l'entraînement complet des paramètres.

      **Fonctionnalités Principales:**
      - Support de 100+ LLMs incluant LLaMA, Mistral, Qwen et plus
      - Multiples méthodes de fine-tuning (LoRA, QLoRA, Full, Freeze)
      - Interface Web intuitive pour une gestion facile des modèles
      - Serveur API intégré pour l'inférence de modèles
      - Support de l'entraînement multi-GPU
      - Capacités de quantification et d'exportation de modèles

      **Configuration Matérielle Requise:**
      - GPU: GPU NVIDIA avec support CUDA requis

      **En Savoir Plus:**
      - [Dépôt GitHub](https://github.com/hiyouga/LLaMA-Factory)
      - [Documentation](https://llamafactory.readthedocs.io/)
    hr_HR: |
      LLaMA Factory je sveobuhvatan okvir za fino podešavanje velikih jezičnih modela (LLMs) s podrškom za preko 100 modela. Pruža korisničko sučelje i snažne metode obuke uključujući LoRA, QLoRA i potpunu obuku parametara.

      **Ključne Značajke:**
      - Podrška za 100+ LLMs uključujući LLaMA, Mistral, Qwen i više
      - Višestruke metode finog podešavanja (LoRA, QLoRA, Full, Freeze)
      - Intuitivno Web sučelje za jednostavno upravljanje modelima
      - Ugrađeni API poslužitelj za inferentiranje modela
      - Podrška za obuku s više GPU-a
      - Mogućnosti kvantizacije i izvoza modela

      **Hardverski Zahtjevi:**
      - GPU: Potreban NVIDIA GPU s CUDA podrškom

      **Saznajte Više:**
      - [GitHub Repozitorij](https://github.com/hiyouga/LLaMA-Factory)
      - [Dokumentacija](https://llamafactory.readthedocs.io/)
    it_IT: |
      LLaMA Factory è un framework completo per il fine-tuning di Large Language Models (LLMs) con supporto per oltre 100 modelli. Fornisce un'interfaccia web user-friendly e potenti metodi di addestramento tra cui LoRA, QLoRA e addestramento a parametri completi.

      **Caratteristiche Principali:**
      - Supporto per 100+ LLMs inclusi LLaMA, Mistral, Qwen e altri
      - Multipli metodi di fine-tuning (LoRA, QLoRA, Full, Freeze)
      - Interfaccia Web intuitiva per una facile gestione dei modelli
      - Server API integrato per l'inferenza dei modelli
      - Supporto per addestramento multi-GPU
      - Capacità di quantizzazione ed esportazione modelli

      **Requisiti Hardware:**
      - GPU: GPU NVIDIA con supporto CUDA richiesta

      **Ulteriori Informazioni:**
      - [Repository GitHub](https://github.com/hiyouga/LLaMA-Factory)
      - [Documentazione](https://llamafactory.readthedocs.io/)
    ja_JP: |
      LLaMA Factoryは、100以上のモデルをサポートする大規模言語モデル(LLMs)のファインチューニング用の包括的なフレームワークです。ユーザーフレンドリーなWebインターフェースと、LoRA、QLoRA、フルパラメータトレーニングなどの強力なトレーニング手法を提供します。

      **主な機能:**
      - LLaMA、Mistral、Qwenなど100以上のLLMsをサポート
      - 複数のファインチューニング手法(LoRA、QLoRA、Full、Freeze)
      - モデル管理を簡単にする直感的なWeb UI
      - モデル推論用の組み込みAPIサーバー
      - マルチGPUトレーニングのサポート
      - 量子化とモデルエクスポート機能

      **ハードウェア要件:**
      - GPU: CUDA対応のNVIDIA GPUが必要

      **詳細情報:**
      - [GitHubリポジトリ](https://github.com/hiyouga/LLaMA-Factory)
      - [ドキュメント](https://llamafactory.readthedocs.io/)
    ko_KR: |
      LLaMA Factory는 100개 이상의 모델을 지원하는 대규모 언어 모델(LLMs) 파인튜닝을 위한 포괄적인 프레임워크입니다. 사용자 친화적인 웹 인터페이스와 LoRA, QLoRA, 전체 매개변수 학습을 포함한 강력한 학습 방법을 제공합니다.

      **주요 기능:**
      - LLaMA, Mistral, Qwen 등 100개 이상의 LLMs 지원
      - 다양한 파인튜닝 방법(LoRA, QLoRA, Full, Freeze)
      - 쉬운 모델 관리를 위한 직관적인 웹 UI
      - 모델 추론을 위한 내장 API 서버
      - 멀티 GPU 학습 지원
      - 양자화 및 모델 내보내기 기능

      **하드웨어 요구사항:**
      - GPU: CUDA 지원 NVIDIA GPU 필요

      **더 알아보기:**
      - [GitHub 저장소](https://github.com/hiyouga/LLaMA-Factory)
      - [문서](https://llamafactory.readthedocs.io/)
    nb_NO: |
      LLaMA Factory er et omfattende rammeverk for finjustering av store språkmodeller (LLMs) med støtte for over 100 modeller. Det tilbyr et brukervennlig webgrensesnitt og kraftfulle treningsmetoder inkludert LoRA, QLoRA og fullparametertrening.

      **Nøkkelfunksjoner:**
      - Støtte for 100+ LLMs inkludert LLaMA, Mistral, Qwen og mer
      - Flere finjusteringsmetoder (LoRA, QLoRA, Full, Freeze)
      - Intuitivt Web UI for enkel modellhåndtering
      - Innebygd API-server for modellinferens
      - Støtte for multi-GPU trening
      - Kvantisering og modelleksport

      **Maskinvarekrav:**
      - GPU: NVIDIA GPU med CUDA-støtte påkrevd

      **Lær Mer:**
      - [GitHub Repository](https://github.com/hiyouga/LLaMA-Factory)
      - [Dokumentasjon](https://llamafactory.readthedocs.io/)
    pt_PT: |
      LLaMA Factory é uma estrutura abrangente para ajuste fino de Modelos de Linguagem Grandes (LLMs) com suporte para mais de 100 modelos. Fornece uma interface web amigável e métodos de treino poderosos, incluindo LoRA, QLoRA e treino de parâmetros completos.

      **Características Principais:**
      - Suporte para 100+ LLMs incluindo LLaMA, Mistral, Qwen e mais
      - Múltiplos métodos de ajuste fino (LoRA, QLoRA, Full, Freeze)
      - Interface Web intuitiva para fácil gestão de modelos
      - Servidor API integrado para inferência de modelos
      - Suporte para treino multi-GPU
      - Capacidades de quantização e exportação de modelos

      **Requisitos de Hardware:**
      - GPU: GPU NVIDIA com suporte CUDA necessária

      **Saiba Mais:**
      - [Repositório GitHub](https://github.com/hiyouga/LLaMA-Factory)
      - [Documentação](https://llamafactory.readthedocs.io/)
    ru_RU: |
      LLaMA Factory — это комплексная платформа для тонкой настройки больших языковых моделей (LLMs) с поддержкой более 100 моделей. Она предоставляет удобный веб-интерфейс и мощные методы обучения, включая LoRA, QLoRA и полное обучение параметров.

      **Основные Функции:**
      - Поддержка 100+ LLMs, включая LLaMA, Mistral, Qwen и другие
      - Множественные методы тонкой настройки (LoRA, QLoRA, Full, Freeze)
      - Интуитивный веб-интерфейс для простого управления моделями
      - Встроенный API-сервер для вывода моделей
      - Поддержка обучения на нескольких GPU
      - Возможности квантования и экспорта моделей

      **Требования к Оборудованию:**
      - GPU: требуется NVIDIA GPU с поддержкой CUDA

      **Узнать Больше:**
      - [Репозиторий GitHub](https://github.com/hiyouga/LLaMA-Factory)
      - [Документация](https://llamafactory.readthedocs.io/)
    sv_SE: |
      LLaMA Factory är ett omfattande ramverk för finjustering av stora språkmodeller (LLMs) med stöd för över 100 modeller. Det tillhandahåller ett användarvänligt webbgränssnitt och kraftfulla träningsmetoder inklusive LoRA, QLoRA och fullständig parameterträning.

      **Nyckelfunktioner:**
      - Stöd för 100+ LLMs inklusive LLaMA, Mistral, Qwen och fler
      - Flera finjusteringsmetoder (LoRA, QLoRA, Full, Freeze)
      - Intuitivt webbgränssnitt för enkel modellhantering
      - Inbyggd API-server för modellinferens
      - Stöd för multi-GPU-träning
      - Kvantisering och modellexport

      **Hårdvarukrav:**
      - GPU: NVIDIA GPU med CUDA-stöd krävs

      **Läs Mer:**
      - [GitHub Repository](https://github.com/hiyouga/LLaMA-Factory)
      - [Dokumentation](https://llamafactory.readthedocs.io/)
    tr_TR: |
      LLaMA Factory, 100'den fazla modeli destekleyen Büyük Dil Modelleri (LLMs) için kapsamlı bir ince ayar çerçevesidir. LoRA, QLoRA ve tam parametre eğitimi dahil olmak üzere kullanıcı dostu bir web arayüzü ve güçlü eğitim yöntemleri sağlar.

      **Ana Özellikler:**
      - LLaMA, Mistral, Qwen ve daha fazlası dahil 100+ LLM desteği
      - Birden fazla ince ayar yöntemi (LoRA, QLoRA, Full, Freeze)
      - Kolay model yönetimi için sezgisel Web Arayüzü
      - Model çıkarımı için yerleşik API sunucusu
      - Çoklu GPU eğitim desteği
      - Kuantizasyon ve model dışa aktarma yetenekleri

      **Donanım Gereksinimleri:**
      - GPU: CUDA desteği olan NVIDIA GPU gerekli

      **Daha Fazla Bilgi:**
      - [GitHub Deposu](https://github.com/hiyouga/LLaMA-Factory)
      - [Dokümantasyon](https://llamafactory.readthedocs.io/)
    zh_CN: |
      LLaMA Factory 是一个全面的大语言模型(LLMs)微调框架,支持超过100个模型。它提供了用户友好的Web界面和强大的训练方法,包括LoRA、QLoRA和全参数训练。

      **主要功能:**
      - 支持100+个LLMs,包括LLaMA、Mistral、Qwen等
      - 多种微调方法(LoRA、QLoRA、Full、Freeze)
      - 直观的Web UI,轻松管理模型
      - 内置API服务器用于模型推理
      - 多GPU训练支持
      - 量化和模型导出功能

      **硬件要求:**
      - GPU: 需要支持CUDA的NVIDIA GPU
      
      **了解更多:**
      - [GitHub Repository](https://github.com/hiyouga/LLaMA-Factory)
      - [官方文档](https://llamafactory.readthedocs.io/)
  developer: hiyouga
  icon: https://cdn.jsdelivr.net/gh/IceWhaleTech/CasaOS-AppStore@main/Apps/LLaMA-Factory_Nvidia/icon.png
  screenshot_link: 
    - https://cdn.jsdelivr.net/gh/IceWhaleTech/CasaOS-AppStore@main/Apps/LLaMA-Factory_Nvidia/screenshot-1.png
    - https://cdn.jsdelivr.net/gh/IceWhaleTech/CasaOS-AppStore@main/Apps/LLaMA-Factory_Nvidia/screenshot-2.png
    - https://cdn.jsdelivr.net/gh/IceWhaleTech/CasaOS-AppStore@main/Apps/LLaMA-Factory_Nvidia/screenshot-3.png
  tagline:
    de_DE: Einheitliche LLM-Feinabstimmung mit 100+ Modellen
    el_GR: Ενοποιημένη ρύθμιση LLM με 100+ μοντέλα
    en_GB: Unified LLM Fine-Tuning with 100+ Models
    en_US: Unified LLM Fine-Tuning with 100+ Models
    fr_FR: Ajustement unifié des LLM avec 100+ modèles
    hr_HR: Jedinstveno fino podešavanje LLM s 100+ modela
    it_IT: Fine-Tuning unificato di LLM con 100+ modelli
    ja_JP: 100以上のモデルで統一されたLLMファインチューニング
    ko_KR: 100개 이상의 모델로 통합된 LLM 파인튜닝
    nb_NO: Enhetlig LLM finjustering med 100+ modeller
    pt_PT: Ajuste fino unificado de LLM com 100+ modelos
    ru_RU: Унифицированная тонкая настройка LLM с 100+ моделями
    sv_SE: Enhetlig LLM-finjustering med 100+ modeller
    tr_TR: 100+ Model ile Birleşik LLM İnce Ayarı
    zh_CN: 统一的LLM微调,支持100+模型
  title:
    de_DE: LLaMA Factory(Nvidia GPU)
    el_GR: LLaMA Factory(Nvidia GPU)
    en_GB: LLaMA Factory(Nvidia GPU)
    en_US: LLaMA Factory(Nvidia GPU)
    fr_FR: LLaMA Factory(Nvidia GPU)
    hr_HR: LLaMA Factory(Nvidia GPU)
    it_IT: LLaMA Factory(Nvidia GPU)
    ja_JP: LLaMA Factory(Nvidia GPU)
    ko_KR: LLaMA Factory(Nvidia GPU)
    nb_NO: LLaMA Factory(Nvidia GPU)
    pt_PT: LLaMA Factory(Nvidia GPU)
    ru_RU: LLaMA Factory(Nvidia GPU)
    sv_SE: LLaMA Factory(Nvidia GPU)
    tr_TR: LLaMA Factory(Nvidia GPU)
    zh_CN: LLaMA Factory(Nvidia GPU)
  index: /
  scheme: http
  main: llama-factory-nvidia
  port_map: "18877"
